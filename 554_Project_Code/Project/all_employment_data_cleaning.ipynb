{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEOMA0AB.csv', 'SEOMA15A.csv', 'SEOMA15B.csv', 'SEOMA2AB.csv', 'SEOMA3AB.csv', 'SEOMA4AB.csv', 'SEOMA5AB.csv', 'SEOMA6AB.csv', 'SEOMA7AB.csv', 'SEOMA8AB.csv', 'SEOMA9AB.csv']\n",
      "['SEOFE0AB.csv', 'SEOFE15A.csv', 'SEOFE15B.csv', 'SEOFE2AB.csv', 'SEOFE3AB.csv', 'SEOFE4AB.csv', 'SEOFE5AB.csv', 'SEOFE6AB.csv', 'SEOFE7AB.csv', 'SEOFE8AB.csv', 'SEOFE9AB.csv']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/\")\n",
    "f_files = []\n",
    "m_files = []\n",
    "male_file = \"share_by_occupation_male.txt\"\n",
    "fem_file = \"share_by_occupation_female.txt\"\n",
    "\n",
    "with open(male_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:    \n",
    "        file = l.rstrip(\"\\n\") + \".csv\"\n",
    "        m_files.append(file)\n",
    "print(m_files)\n",
    "\n",
    "\n",
    "with open(fem_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:    \n",
    "        file = l.rstrip(\"\\n\") + \".csv\"\n",
    "        f_files.append(file)\n",
    "print(f_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(f_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 11 csv files for male\n",
      "Using 11 csv files for female\n"
     ]
    }
   ],
   "source": [
    "# Read csv files from No Ceilings project folder\n",
    "path = \"/Users/ericaxia/Downloads/Github/project-girlboss/data/noceilings-data-master/csv\"\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "result = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "# Narrow down to just the files I want\n",
    "m_result = [f for f in result if f in m_files]\n",
    "dfs_male = []\n",
    "for f in m_result:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs_male.append((f, df))    \n",
    "print(f\"Using {len(dfs_male)} csv files for male\")\n",
    "\n",
    "f_result = [f for f in result if f in f_files]\n",
    "dfs_female = []\n",
    "for f in f_result:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs_female.append((f, df))    \n",
    "print(f\"Using {len(dfs_female)} csv files for female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's narrow down to a chosen year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/d3layout_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW: map ISO -> Country name for better understandability in graph\n",
    "with open('iso_to_country_names.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    country_names = {rows[0]: rows[1] for rows in reader}\n",
    "    # print(country_names)\n",
    "\n",
    "country_names_dict = { v: k for k, v in country_names.items()}\n",
    "# country_names_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_iso_to_name(iso):\n",
    "    # print(x)\n",
    "    if iso in country_names_dict:\n",
    "        return country_names_dict[iso]\n",
    "    else:\n",
    "        return iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISO</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BGR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KHM</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HRV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CYP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CZE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DNK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DEU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GRC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ISL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IRL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ITA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LTU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MKD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PRT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ROU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SGP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ESP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SWE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CHE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ACE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.21562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ECM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ECE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.71799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td># Series: SEOFE15A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td># Name: Share employed by occupation, 1A - Man...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td># Definition: Share of women that are Managers.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td># Source: International Labour Organization (I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td># Data from the No Ceilings project: http://no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td># For more about the data, please visit http:/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ISO  2009  2010  2011  \\\n",
       "0                                                 AUT   NaN   NaN   3.0   \n",
       "1                                                 BEL   NaN   NaN   4.7   \n",
       "2                                                 BGR   NaN   NaN   4.9   \n",
       "3                                                 KHM   0.2   0.2   0.2   \n",
       "4                                                 HRV   NaN   NaN   2.4   \n",
       "5                                                 CYP   NaN   NaN   1.2   \n",
       "6                                                 CZE   NaN   NaN   2.8   \n",
       "7                                                 DNK   NaN   NaN   1.6   \n",
       "8                                                 EST   NaN   NaN   6.5   \n",
       "9                                                 FIN   NaN   NaN   3.4   \n",
       "10                                                FRA   NaN   NaN   6.2   \n",
       "11                                                DEU   NaN   NaN   3.2   \n",
       "12                                                GRC   NaN   NaN   2.4   \n",
       "13                                                HUN   NaN   NaN   5.0   \n",
       "14                                                ISL   NaN   NaN   7.5   \n",
       "15                                                IRL   NaN   NaN   5.3   \n",
       "16                                                ITA   NaN   NaN   2.4   \n",
       "17                                                LVA   NaN   NaN   8.9   \n",
       "18                                                LTU   NaN   NaN   6.9   \n",
       "19                                                LUX   NaN   NaN   2.4   \n",
       "20                                                MKD   NaN   NaN   4.1   \n",
       "21                                                MLT   NaN   NaN   5.8   \n",
       "22                                                NLD   NaN   NaN   4.7   \n",
       "23                                                NOR   NaN   NaN   4.3   \n",
       "24                                                POL   NaN   NaN   5.2   \n",
       "25                                                PRT   NaN   NaN   4.3   \n",
       "26                                                ROU   NaN   NaN   1.5   \n",
       "27                                                SGP   NaN   NaN   NaN   \n",
       "28                                                SVK   NaN   NaN   3.7   \n",
       "29                                                SVN   NaN   NaN   6.9   \n",
       "30                                                ESP   NaN   NaN   3.3   \n",
       "31                                                SWE   NaN   NaN   3.9   \n",
       "32                                                CHE   NaN   NaN   5.7   \n",
       "33                                                TUR   NaN   NaN   NaN   \n",
       "34                                                GBR   NaN   NaN   7.6   \n",
       "35                                                ACE   NaN   NaN   NaN   \n",
       "36                                                ECM   NaN   NaN   NaN   \n",
       "37                                                ECE   NaN   NaN   NaN   \n",
       "38                                 # Series: SEOFE15A   NaN   NaN   NaN   \n",
       "39  # Name: Share employed by occupation, 1A - Man...   NaN   NaN   NaN   \n",
       "40    # Definition: Share of women that are Managers.   NaN   NaN   NaN   \n",
       "41  # Source: International Labour Organization (I...   NaN   NaN   NaN   \n",
       "42  # Data from the No Ceilings project: http://no...   NaN   NaN   NaN   \n",
       "43  # For more about the data, please visit http:/...   NaN   NaN   NaN   \n",
       "\n",
       "        2012  \n",
       "0    2.90000  \n",
       "1    5.80000  \n",
       "2    4.70000  \n",
       "3        NaN  \n",
       "4    2.50000  \n",
       "5    1.30000  \n",
       "6    3.10000  \n",
       "7    1.10000  \n",
       "8    5.80000  \n",
       "9    2.30000  \n",
       "10   6.10000  \n",
       "11   3.00000  \n",
       "12   2.70000  \n",
       "13   4.10000  \n",
       "14   8.40000  \n",
       "15   5.50000  \n",
       "16   2.30000  \n",
       "17   8.20000  \n",
       "18   6.80000  \n",
       "19   1.20000  \n",
       "20   3.10000  \n",
       "21   6.80000  \n",
       "22   4.30000  \n",
       "23   4.50000  \n",
       "24   5.30000  \n",
       "25   4.70000  \n",
       "26   1.50000  \n",
       "27  13.00000  \n",
       "28   3.30000  \n",
       "29   6.70000  \n",
       "30   3.30000  \n",
       "31   4.30000  \n",
       "32   5.90000  \n",
       "33   2.50000  \n",
       "34   7.70000  \n",
       "35   4.21562  \n",
       "36   4.10000  \n",
       "37   2.71799  \n",
       "38       NaN  \n",
       "39       NaN  \n",
       "40       NaN  \n",
       "41       NaN  \n",
       "42       NaN  \n",
       "43       NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_female[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "def clean_dfs(dfs, gender, year):\n",
    "    countries = []\n",
    "    json_names = []\n",
    "    for i in range(len(dfs)):\n",
    "        name = dfs[i][0].strip(\".csv\")\n",
    "        df = dfs[i][1]\n",
    "        df = df[['ISO', year]]\n",
    "        df.dropna(inplace=True)  # drop nans\n",
    "        df.columns = ['name', 'value']  # rename cols\n",
    "        # change ISO to full country\n",
    "        df['name'] = df['name'].apply(lambda x: convert_iso_to_name(x))\n",
    "        df['gender'] = gender  # set gender as new column\n",
    "        # drop weird ones that dont match any full country name\n",
    "        df = df[~df[\"name\"].str.isupper()]\n",
    "        shapes.append(df.shape)\n",
    "        ## EXPORT\n",
    "        # df.to_json(f\"{name}.json\", orient='records')  # export to json\n",
    "        # print(f\"Exported {name} data with shape {df.shape}\")\n",
    "        json_names.append(f\"{name}.json\")\n",
    "        # # get unique countries\n",
    "        names = list(df['name'].unique())\n",
    "        countries.append(names)\n",
    "    return json_names, countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n",
      "/var/folders/mm/jp6_fd4x0g126l5m3dfnk4k80000gn/T/ipykernel_18158/3941417616.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['name'] = df['name'].apply(lambda x: convert_iso_to_name(x))\n",
      "/var/folders/mm/jp6_fd4x0g126l5m3dfnk4k80000gn/T/ipykernel_18158/3941417616.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['gender'] = gender  # set gender as new column\n"
     ]
    }
   ],
   "source": [
    "year = '2012'  # chosen year for plot\n",
    "json_names_fem, countries_f = clean_dfs(dfs_female, 'female', year)\n",
    "json_names_male, countries_m = clean_dfs(dfs_male, 'male', year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for tup in shapes:\n",
    "    nrows = tup[0]\n",
    "    c += nrows\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "{'Bulgaria', 'Portugal', 'Iceland', 'Italy', 'Austria', 'Belgium', 'Luxembourg', 'Moldova', 'Cyprus', 'Turkey', 'Ireland', 'Croatia', 'Netherlands', 'Singapore', 'Spain', 'Romania', 'Poland', 'Hungary', 'Denmark', 'United Kingdom', 'Finland', 'Greece', 'Malta', 'Lithuania', 'Slovenia', 'Czech Republic', 'Germany', 'North Macedonia', 'Switzerland', 'Norway', 'Slovak Republic', 'Estonia', 'Sweden', 'France', 'Latvia'}\n"
     ]
    }
   ],
   "source": [
    "countries_ff = set(functools.reduce(operator.iconcat, countries_f, []))\n",
    "countries_mm = set(functools.reduce(operator.iconcat, countries_m, []))\n",
    "all_countries = countries_ff.union(countries_mm)\n",
    "print(len(all_countries))\n",
    "print(all_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('countries_2012.txt', \"w\") as f:\n",
    "#     for c in all_countries:\n",
    "#         f.write(c + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How many countries across all years and not just 2012?\n",
    "# countries = set()\n",
    "# for df in dfs_female:\n",
    "#     name = df[0].strip(\".csv\")\n",
    "#     df = df[1]\n",
    "#     # df = df[['ISO', year]]\n",
    "#     # df.dropna(inplace=True)  # drop nans\n",
    "#     # df.columns = ['name', 'value']  # rename cols\n",
    "#     # change ISO to full country\n",
    "#     df['name'] = df['ISO'].apply(lambda x: convert_iso_to_name(x))\n",
    "#     df_countries = (df['name'].unique())\n",
    "#     for c in df_countries:\n",
    "#         # remove non-countries\n",
    "#         if not c.startswith(\"#\") and not c.isupper():\n",
    "#             countries.add(c)  \n",
    "#             if c == \"United States\":\n",
    "#                 print(df[df['name']==c])  \n",
    "# print(len(countries)) # 120 countries across all years, w/o dropping any nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal nested JSON format as final product\n",
    "That we can plug right into the zoomable circle packing chart \n",
    "Let names = country or code code, values = percentage \n",
    "\n",
    "```\n",
    "{\n",
    "    \"name\": \"education\",\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"name\": \"Primary School Education, Women age 25+\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"value\": 95,\n",
    "                    \"name\": \"USA\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Secondary School Education, Women age 25+\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"value\": 96,\n",
    "                    \"name\": \"USA\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## continue where i left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back in the json files saved\n",
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/d3layout_data\")\n",
    "extension = 'json'\n",
    "result = glob.glob('*.{}'.format(extension))\n",
    "# Narrow down to just the files I want\n",
    "f_result = [f for f in result if f in json_names_fem]\n",
    "m_result = [f for f in result if f in json_names_male]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file with full dataset name mappings\n",
    "with open('data_names_male.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    dataset_names_male = {rows[0]: rows[1].rstrip(\", Male\") for rows in reader}\n",
    "    print(dataset_names_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file with full dataset name mappings\n",
    "with open('data_names.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    dataset_names_female = {rows[0]: rows[1].rstrip(\", Female\") for rows in reader}\n",
    "    print(dataset_names_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create big json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = defaultdict(list)\n",
    "# female\n",
    "for f in f_result:\n",
    "    ds_code = f.split('.json')[0]\n",
    "    ds_name = dataset_names_female[ds_code]\n",
    "    # print(ds_name)\n",
    "    with open(f, \"r\") as read_file:\n",
    "        data = json.load(read_file)  # list of dicts\n",
    "        data_dict[ds_name].append(data)\n",
    "# print(len(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male\n",
    "for f in m_result:\n",
    "    ds_code = f.split('.json')[0]\n",
    "    ds_name = dataset_names_male[ds_code]\n",
    "    print(ds_name)\n",
    "    with open(f, \"r\") as read_file:\n",
    "        data = json.load(read_file)  # list of dicts\n",
    "        data_dict[ds_name].append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for occupation, list of lists ([male list], [female list]) \n",
    "## flatten the list of lists\n",
    "data_dict2 = defaultdict(list)\n",
    "for occ, lol in data_dict.items():\n",
    "    print(occ)\n",
    "    if len(lol) == 2:\n",
    "        data_dict2[occ] = lol[0] + lol[1]\n",
    "    elif len(lol) == 1:\n",
    "        data_dict2[occ] = lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_file = { \"name\": \"employment\", \"children\": [] }\n",
    "\n",
    "for occ, l in data_dict2.items():\n",
    "    inner_dict = { \"name\": occ, \"children\": l }\n",
    "    export_file[\"children\"].append(inner_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(export_file['children']))\n",
    "print(type(export_file['children']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"all_employment_data.json\", \"w\") as write_file:\n",
    "#     json.dump(export_file, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
