{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEOMA0AB.csv', 'SEOMA15A.csv', 'SEOMA15B.csv', 'SEOMA2AB.csv', 'SEOMA3AB.csv', 'SEOMA4AB.csv', 'SEOMA5AB.csv', 'SEOMA6AB.csv', 'SEOMA7AB.csv', 'SEOMA8AB.csv', 'SEOMA9AB.csv']\n",
      "['SEOFE0AB.csv', 'SEOFE15A.csv', 'SEOFE15B.csv', 'SEOFE2AB.csv', 'SEOFE3AB.csv', 'SEOFE4AB.csv', 'SEOFE5AB.csv', 'SEOFE6AB.csv', 'SEOFE7AB.csv', 'SEOFE8AB.csv', 'SEOFE9AB.csv']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/\")\n",
    "f_files = []\n",
    "m_files = []\n",
    "male_file = \"share_by_occupation_male.txt\"\n",
    "fem_file = \"share_by_occupation_female.txt\"\n",
    "\n",
    "with open(male_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:    \n",
    "        file = l.rstrip(\"\\n\") + \".csv\"\n",
    "        m_files.append(file)\n",
    "print(m_files)\n",
    "\n",
    "\n",
    "with open(fem_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:    \n",
    "        file = l.rstrip(\"\\n\") + \".csv\"\n",
    "        f_files.append(file)\n",
    "print(f_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(f_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 11 csv files for male\n",
      "Using 11 csv files for female\n"
     ]
    }
   ],
   "source": [
    "# Read csv files from No Ceilings project folder\n",
    "path = \"/Users/ericaxia/Downloads/Github/project-girlboss/data/noceilings-data-master/csv\"\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "result = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "# Narrow down to just the files I want\n",
    "m_result = [f for f in result if f in m_files]\n",
    "dfs_male = []\n",
    "for f in m_result:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs_male.append((f, df))    \n",
    "print(f\"Using {len(dfs_male)} csv files for male\")\n",
    "\n",
    "f_result = [f for f in result if f in f_files]\n",
    "dfs_female = []\n",
    "for f in f_result:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs_female.append((f, df))    \n",
    "print(f\"Using {len(dfs_female)} csv files for female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's narrow down to a chosen year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/d3layout_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW: map ISO -> Country name for better understandability in graph\n",
    "with open('iso_to_country_names.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    country_names = {rows[0]: rows[1] for rows in reader}\n",
    "    # print(country_names)\n",
    "\n",
    "country_names_dict = { v: k for k, v in country_names.items()}\n",
    "# country_names_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_iso_to_name(iso):\n",
    "    # print(x)\n",
    "    if iso in country_names_dict:\n",
    "        return country_names_dict[iso]\n",
    "    else:\n",
    "        return iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = []\n",
    "def clean_dfs(dfs, gender, year):\n",
    "    countries = []\n",
    "    json_names = []\n",
    "    for i in range(len(dfs)):\n",
    "        name = dfs[i][0].strip(\".csv\")\n",
    "        df = dfs[i][1]\n",
    "        df = df[['ISO', year]]\n",
    "        df.dropna(inplace=True)  # drop nans\n",
    "        df.columns = ['name', 'value']  # rename cols\n",
    "        # change ISO to full country\n",
    "        df['name'] = df['name'].apply(lambda x: convert_iso_to_name(x))\n",
    "        df['gender'] = gender  # set gender as new column\n",
    "        # drop weird ones that dont match any full country name\n",
    "        df = df[~df[\"name\"].str.isupper()]\n",
    "        shapes.append(df.shape)\n",
    "        ## EXPORT\n",
    "        # df.to_json(f\"{name}.json\", orient='records')  # export to json\n",
    "        # print(f\"Exported {name} data with shape {df.shape}\")\n",
    "        json_names.append(f\"{name}.json\")\n",
    "        # # get unique countries\n",
    "        names = list(df['name'].unique())\n",
    "        countries.append(names)\n",
    "    return json_names, countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n",
      "/var/folders/mm/jp6_fd4x0g126l5m3dfnk4k80000gn/T/ipykernel_18158/3941417616.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['name'] = df['name'].apply(lambda x: convert_iso_to_name(x))\n",
      "/var/folders/mm/jp6_fd4x0g126l5m3dfnk4k80000gn/T/ipykernel_18158/3941417616.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['gender'] = gender  # set gender as new column\n"
     ]
    }
   ],
   "source": [
    "year = '2012'  # chosen year for plot\n",
    "json_names_fem, countries_f = clean_dfs(dfs_female, 'female', year)\n",
    "json_names_male, countries_m = clean_dfs(dfs_male, 'male', year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for tup in shapes:\n",
    "    nrows = tup[0]\n",
    "    c += nrows\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "{'Bulgaria', 'Portugal', 'Iceland', 'Italy', 'Austria', 'Belgium', 'Luxembourg', 'Moldova', 'Cyprus', 'Turkey', 'Ireland', 'Croatia', 'Netherlands', 'Singapore', 'Spain', 'Romania', 'Poland', 'Hungary', 'Denmark', 'United Kingdom', 'Finland', 'Greece', 'Malta', 'Lithuania', 'Slovenia', 'Czech Republic', 'Germany', 'North Macedonia', 'Switzerland', 'Norway', 'Slovak Republic', 'Estonia', 'Sweden', 'France', 'Latvia'}\n"
     ]
    }
   ],
   "source": [
    "countries_ff = set(functools.reduce(operator.iconcat, countries_f, []))\n",
    "countries_mm = set(functools.reduce(operator.iconcat, countries_m, []))\n",
    "all_countries = countries_ff.union(countries_mm)\n",
    "print(len(all_countries))\n",
    "print(all_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('countries_2012.txt', \"w\") as f:\n",
    "#     for c in all_countries:\n",
    "#         f.write(c + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How many countries across all years and not just 2012?\n",
    "# countries = set()\n",
    "# for df in dfs_female:\n",
    "#     name = df[0].strip(\".csv\")\n",
    "#     df = df[1]\n",
    "#     # df = df[['ISO', year]]\n",
    "#     # df.dropna(inplace=True)  # drop nans\n",
    "#     # df.columns = ['name', 'value']  # rename cols\n",
    "#     # change ISO to full country\n",
    "#     df['name'] = df['ISO'].apply(lambda x: convert_iso_to_name(x))\n",
    "#     df_countries = (df['name'].unique())\n",
    "#     for c in df_countries:\n",
    "#         # remove non-countries\n",
    "#         if not c.startswith(\"#\") and not c.isupper():\n",
    "#             countries.add(c)  \n",
    "#             if c == \"United States\":\n",
    "#                 print(df[df['name']==c])  \n",
    "# print(len(countries)) # 120 countries across all years, w/o dropping any nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal nested JSON format as final product\n",
    "That we can plug right into the zoomable circle packing chart \n",
    "Let names = country or code code, values = percentage \n",
    "\n",
    "```\n",
    "{\n",
    "    \"name\": \"education\",\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"name\": \"Primary School Education, Women age 25+\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"value\": 95,\n",
    "                    \"name\": \"USA\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Secondary School Education, Women age 25+\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"value\": 96,\n",
    "                    \"name\": \"USA\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## continue where i left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back in the json files saved\n",
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/d3layout_data\")\n",
    "extension = 'json'\n",
    "result = glob.glob('*.{}'.format(extension))\n",
    "# Narrow down to just the files I want\n",
    "f_result = [f for f in result if f in json_names_fem]\n",
    "m_result = [f for f in result if f in json_names_male]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file with full dataset name mappings\n",
    "with open('data_names_male.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    dataset_names_male = {rows[0]: rows[1].rstrip(\", Male\") for rows in reader}\n",
    "    print(dataset_names_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file with full dataset name mappings\n",
    "with open('data_names.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    dataset_names_female = {rows[0]: rows[1].rstrip(\", Female\") for rows in reader}\n",
    "    print(dataset_names_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create big json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = defaultdict(list)\n",
    "# female\n",
    "for f in f_result:\n",
    "    ds_code = f.split('.json')[0]\n",
    "    ds_name = dataset_names_female[ds_code]\n",
    "    # print(ds_name)\n",
    "    with open(f, \"r\") as read_file:\n",
    "        data = json.load(read_file)  # list of dicts\n",
    "        data_dict[ds_name].append(data)\n",
    "# print(len(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male\n",
    "for f in m_result:\n",
    "    ds_code = f.split('.json')[0]\n",
    "    ds_name = dataset_names_male[ds_code]\n",
    "    print(ds_name)\n",
    "    with open(f, \"r\") as read_file:\n",
    "        data = json.load(read_file)  # list of dicts\n",
    "        data_dict[ds_name].append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for occupation, list of lists ([male list], [female list]) \n",
    "## flatten the list of lists\n",
    "data_dict2 = defaultdict(list)\n",
    "for occ, lol in data_dict.items():\n",
    "    print(occ)\n",
    "    if len(lol) == 2:\n",
    "        data_dict2[occ] = lol[0] + lol[1]\n",
    "    elif len(lol) == 1:\n",
    "        data_dict2[occ] = lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_file = { \"name\": \"employment\", \"children\": [] }\n",
    "\n",
    "for occ, l in data_dict2.items():\n",
    "    inner_dict = { \"name\": occ, \"children\": l }\n",
    "    export_file[\"children\"].append(inner_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(export_file['children']))\n",
    "print(type(export_file['children']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"all_employment_data.json\", \"w\") as write_file:\n",
    "#     json.dump(export_file, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
