{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/\")\n",
    "csv_files = []\n",
    "myfile = \"share_by_occupation_female.txt\"\n",
    "# text file where I specify which files I want to use\n",
    "with open(myfile, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:    \n",
    "        file = l.rstrip(\"\\n\") + \".csv\"\n",
    "        csv_files.append(file)\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files from No Ceilings project folder\n",
    "path = \"/Users/ericaxia/Downloads/Github/project-girlboss/data/noceilings-data-master/csv\"\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "result = glob.glob('*.{}'.format(extension))\n",
    "# print(result)\n",
    "# Narrow down to just the files I want\n",
    "result2 = [f for f in result if f in csv_files]\n",
    "dfs = []\n",
    "for f in result2:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs.append((f, df))    \n",
    "print(f\"Using {len(dfs)} csv files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dfs[0][1]\n",
    "# # df.head()\n",
    "# # df.tail(10)\n",
    "# # ## gets rid of text dscrip at bottom\n",
    "# # df_us = df_us.iloc[0:121, :]\n",
    "# # # df_us.tail()\n",
    "# col_nulls = df.isna().sum().sort_values()\n",
    "# c = col_nulls.to_frame()\n",
    "# c.reset_index(inplace=True)\n",
    "# c.columns = ['Country', 'Num Nulls']\n",
    "# print(c.iloc[0:4])\n",
    "# # ## pick a year with low amonut of nans\n",
    "# # ## e.g. 2012 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Which year has least amount of missing data?\n",
    "# for tup in dfs:\n",
    "#     print(tup[0])\n",
    "#     df_us = tup[1]\n",
    "#     df_us = df_us.iloc[0:121, :]\n",
    "#     col_nulls = df_us.isna().sum().sort_values()\n",
    "#     c = col_nulls.to_frame()\n",
    "#     c.reset_index(inplace=True)\n",
    "#     c.columns = ['Country', 'Num Nulls']\n",
    "#     print(c.iloc[0:4])\n",
    "#     ## pick a year with low amonut of nans\n",
    "#     ## e.g. 2012 seems like year that all DFs have low nans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's narrow down to a chosen year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/d3layout_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW: map ISO -> Country name for better understandability in graph\n",
    "with open('iso_to_country_names.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    country_names = {rows[0]: rows[1] for rows in reader}\n",
    "    # print(country_names)\n",
    "\n",
    "country_names_dict = { v: k for k, v in country_names.items()}\n",
    "# country_names_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_iso_to_name(iso):\n",
    "    # print(x)\n",
    "    if iso in country_names_dict:\n",
    "        return country_names_dict[iso]\n",
    "    else:\n",
    "        return iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year = '2012'  # chosen year to graph\n",
    "\n",
    "json_names = []\n",
    "dfs_to_plot = []\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    # as a test, use first df for now\n",
    "    name = dfs[i][0].strip(\".csv\")\n",
    "    df = dfs[i][1]\n",
    "    # df = df.iloc[0:121, :] # TODO: better way to get rid of bottom text?\n",
    "    df = df[['ISO', year]]\n",
    "\n",
    "    # drop nans\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df.columns = ['name', 'value']\n",
    "    \n",
    "\n",
    "    df['name'] = df['name'].apply(lambda x: convert_iso_to_name(x))\n",
    "\n",
    "    dfs_to_plot.append((name, df))\n",
    "\n",
    "    df.to_json(f\"{name}.json\", orient='records')\n",
    "    print(f\"Exported {name} data with shape {df.shape}\")\n",
    "    json_names.append(f\"{name}.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = dfs_to_plot[0][0]\n",
    "df = dfs_to_plot[0][1]\n",
    "# print(name)\n",
    "\n",
    "df.columns = ['name', 'value']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Percent of Female Managers, by Country\")\n",
    "plt.xticks(rotation = 45)\n",
    "sns.barplot(data=df, x='name', y='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideal nested JSON format as final product\n",
    "That we can plug right into the zoomable circle packing chart \n",
    "Let names = country or code code, values = percentage \n",
    "\n",
    "```\n",
    "{\n",
    "    \"name\": \"education\",\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"name\": \"Primary School Education, Women age 25+\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"value\": 95,\n",
    "                    \"name\": \"USA\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Secondary School Education, Women age 25+\",\n",
    "            \"children\": [\n",
    "                {\n",
    "                    \"value\": 96,\n",
    "                    \"name\": \"USA\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## continue where i left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back in the json files saved\n",
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/d3layout_data\")\n",
    "extension = 'json'\n",
    "result = glob.glob('*.{}'.format(extension))\n",
    "# Narrow down to just the files I want\n",
    "result2 = [f for f in result if f in json_names]\n",
    "# print(len(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file with full dataset name mappings\n",
    "with open('data_names.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    dataset_names = {rows[0]: rows[1] for rows in reader}\n",
    "    # print(dataset_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create big json file\n",
    "\n",
    "export_file = { \"name\": \"employment\", \"children\": [] }\n",
    "\n",
    "for f in result2:\n",
    "    ds_code = f.split('.json')[0]\n",
    "    ds_name = dataset_names[ds_code]\n",
    "    # print(ds_name)\n",
    "    with open(f, \"r\") as read_file:\n",
    "        data = json.load(read_file)  # list of dicts\n",
    "        inner_dict = { \"name\": ds_name, \"children\": data }\n",
    "        export_file[\"children\"].append(inner_dict)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"female_employment_data.json\", \"w\") as write_file:\n",
    "    json.dump(export_file, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
