{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly wages for females and males\n",
    "In LOCAL CURRENCY UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import functools\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install easymoney\n",
    "# from easymoney.money import EasyPeasy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv files from No Ceilings project folder\n",
    "path = \"/Users/ericaxia/Downloads/Github/project-girlboss/data/noceilings-data-master/csv\"\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "result = glob.glob('*.{}'.format(extension))\n",
    "# Narrow down to just the files I want\n",
    "files = ['MONWAGFE.csv', 'MONWAGMA.csv']\n",
    "dfs = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    dfs.append((f, df))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's narrow down to a chosen year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/ericaxia/Downloads/Github/dsci554/554_Project_Code/Project/d3layout_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import US specific data (median dollar earnings per month)\n",
    "us_data = pd.read_csv(\"median_US_earnings.csv\")\n",
    "us_data.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_fem = dfs[0][1]  # monthly wages for females\n",
    "wages_m = dfs[1][1] # monthly wages for males\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_fem = wages_fem.iloc[0:85, :]  # rm bottom descrip rows\n",
    "wages_m = wages_m.iloc[0:85, :]  # rm bottom descrip rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow down to countries that DO have data for 2011\n",
    "wages_fem = wages_fem[~wages_fem['2011'].isna()]\n",
    "wages_m = wages_m[~wages_m['2011'].isna()]\n",
    "print(wages_fem.shape, wages_m.shape) # (26,18) -> we have 26 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_fem = wages_fem.fillna(axis=0, method='pad')\n",
    "wages_m = wages_m.fillna(axis=0, method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wages_fem.isna().sum().sum())\n",
    "print(wages_m.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process us data separartely\n",
    "us_data2 = us_data.transpose()\n",
    "us_data2.columns = us_data2.iloc[0,:]\n",
    "# us_data2['ISO'] = 'USA'\n",
    "wages_fem_us = pd.DataFrame(us_data2.iloc[1,:])\n",
    "wages_m_us = pd.DataFrame(us_data2.iloc[2,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_m_us.rename(columns={'male': 'value'}, inplace=True)\n",
    "wages_fem_us.rename(columns={'female': 'value'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_fem_us['gender'] = 'female'\n",
    "wages_fem_us.reset_index(inplace=True)\n",
    "wages_m_us['gender'] = 'male'\n",
    "wages_m_us.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_us = pd.concat([wages_fem_us, wages_m_us], axis=0)\n",
    "wages_us['ISO'] = 'USA'\n",
    "wages_us2 = wages_us[wages_us['year'] != 'ISO']\n",
    "# wages_us2.drop(labels='index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wages_us2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine BOTH genders one dataset for ONE country\n",
    "\"\"\" \n",
    "1. Narrow down country\n",
    "2. Separately for each M / F dataset, melt the dataset\n",
    "3. concat the melted datasets together\n",
    "\"\"\"\n",
    "all_countries = pd.DataFrame()\n",
    "countries = list(wages_fem['ISO'].unique())\n",
    "countries.remove(\"MLT\")\n",
    "\n",
    "\n",
    "## Choose a country\n",
    "for c in countries:\n",
    "# c = 'AUS'\n",
    "    f1 = wages_fem[wages_fem['ISO'] == c]\n",
    "    f2 = f1.melt().iloc[1:, :]\n",
    "    f2.columns = ['year', 'value']\n",
    "    f2['gender'] = 'female'\n",
    "    m1 = wages_m[wages_m['ISO'] == c]\n",
    "    m2 = m1.melt().iloc[1:, :]\n",
    "    m2.columns = ['year', 'value']\n",
    "    m2['gender'] = 'male'\n",
    "    all = pd.concat([f2, m2], axis=0)\n",
    "    all2 = all[all['year'] != 'gender']\n",
    "    all2['ISO'] = c\n",
    "    # all2.head()\n",
    "    all_countries = pd.concat([all_countries, all2], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_countries.head()\n",
    "print(all_countries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_countries.reset_index(inplace=True)\n",
    "# wages_us2.reset_index(inplace=True)\n",
    "all_countries2 = pd.concat([all_countries, wages_us2], axis=0)\n",
    "print(all_countries2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for missing values\n",
    "# df.isna().sum().sort_values(ascending=False)\n",
    "# df.drop(labels='index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_countries2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map ISO -> Country name for better understandability in graph\n",
    "with open('iso_to_country_names.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    country_names = {rows[0]: rows[1] for rows in reader}\n",
    "country_names_dict = { v: k for k, v in country_names.items()}\n",
    "def convert_iso_to_name(iso):\n",
    "    if iso in country_names_dict:\n",
    "        return country_names_dict[iso]\n",
    "    else:\n",
    "        return iso\n",
    "# df['country'] = df['ISO']\n",
    "df['country'] = df['ISO'].apply(convert_iso_to_name)\n",
    "# df.drop(labels='ISO', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ISO to currency codes\n",
    "df['currency'] = df['ISO']\n",
    "df['currency'] = df['currency'].str.replace(\"ECU\", \"USD\") # ecuador uses USD\n",
    "df['currency'] = df['currency'].str.replace(\"DEU\", \"EUR\") # germany uses the Euro\n",
    "df['currency'] = df['currency'].str.replace(\"GTM\", \"GTQ\")\n",
    "df['currency'] = df['currency'].str.replace(\"ISL\", \"ISK\")\n",
    "df['currency'] = df['currency'].str.replace(\"USA\", \"USD\")\n",
    "df['currency'] = df['currency'].str.replace(\"LVA\", \"EUR\")\n",
    "df['currency'] = df['currency'].str.replace(\"LUX\", \"EUR\")\n",
    "df['currency'] = df['currency'].str.replace(\"MEX\", \"MXN\")\n",
    "df['currency'] = df['currency'].str.replace(\"MNG\", \"MNT\")\n",
    "df['currency'] = df['currency'].str.replace(\"NZL\", \"NZD\")\n",
    "df['currency'] = df['currency'].str.replace(\"NOR\", \"NOK\")\n",
    "df['currency'] = df['currency'].str.replace(\"PAK\", \"PKR\")\n",
    "df['currency'] = df['currency'].str.replace(\"PHL\", \"PHP\")\n",
    "df['currency'] = df['currency'].str.replace(\"QAT\", \"QAR\")\n",
    "df['currency'] = df['currency'].str.replace(\"SGP\", \"SGD\")\n",
    "df['currency'] = df['currency'].str.replace(\"SVK\", \"EUR\")\n",
    "df['currency'] = df['currency'].str.replace(\"ESP\", \"EUR\")\n",
    "df['currency'] = df['currency'].str.replace(\"SWE\", \"SEK\") # sweden\n",
    "df['currency'] = df['currency'].str.replace(\"SYR\", \"SYP\") # syrian\n",
    "df['currency'] = df['currency'].str.replace(\"THA\", \"THB\") \n",
    "df['currency'] = df['currency'].str.replace(\"UKR\", \"UAH\")\n",
    "df['currency'] = df['currency'].str.replace(\"GBR\", \"GBP\") \n",
    "df['currency'] = df['currency'].str.replace(\"URY\", \"UYU\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## convert local currency to USD\n",
    "# ## for D3 chart so the axes are consistent\n",
    "\n",
    "# ## TODO: stupid bank error.  can we use google sheets or some other way convert the currency?\n",
    "\n",
    "# ep = EasyPeasy() \n",
    "# df['converted_value'] = df.apply(lambda x: ep.currency_converter(x['value'], from_currency=x['currency'], to_currency=\"USD\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df['value'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['year', 'country', 'value', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"wages.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erins = ['New Zealand',\n",
    "         'Japan',\n",
    "         'United States',\n",
    "         'Canada',\n",
    "         'United Kingdom',\n",
    "         'Sweden',\n",
    "         'Norway',\n",
    "         'Korea',\n",
    "         'Slovak Republic',\n",
    "         'Austria',\n",
    "         'Mexico',\n",
    "         'Australia',\n",
    "         'Hungary',\n",
    "         'Czech Republic',\n",
    "         'Germany',\n",
    "         'Finland',\n",
    "         'Portugal',\n",
    "         'Israel',\n",
    "         'Colombia',\n",
    "         'Belgium',\n",
    "         'Denmark',\n",
    "         'Greece',\n",
    "         'France',\n",
    "         'Iceland',\n",
    "         'Costa Rica']\n",
    "\n",
    "print(len(erins))\n",
    "\n",
    "erins2 = set(erins)\n",
    "mycountries = df['country']\n",
    "print(\"Num countries in common:\",len(erins2.intersection(mycountries))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
